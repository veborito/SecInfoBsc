{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Federated Learning for Distributed Network Anomaly Detection\n",
    "\n",
    "### Centralized Federated Learning Workflow\n",
    "\n",
    "![image.png](res/flworkflow.png)\n",
    "\n",
    "### Centralized Federated Learning Training Loop\n",
    "\n",
    "![image-2.png](res/flloop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Send the same initialized model to clients\n",
    "2. Each client trains the local model with E steps of SGD (e.g., one epoch)\n",
    "3. Each client sends model back to aggregation server\n",
    "4. Server aggregates model according to a Strategy\n",
    "5. (optional) Server can perform centralized evaluation of model on global validation dataset. Or ask clients to also send evaluation of local/global model on local validation set\n",
    "6. Server sends aggregated model to clients\n",
    "7. (optional) Exit loop if model \n",
    "8. Go to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: flwr[simulation]\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from pandas->datasets) (2022.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flwr_datasets in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets<=3.1.0,>=2.14.6 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (3.1.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.7.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow==16.1.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (16.1.0)\n",
      "Requirement already satisfied: seaborn<0.14.0,>=0.13.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (0.13.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from flwr_datasets) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.16.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.11.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (2.8.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets<=3.1.0,>=2.14.6->flwr_datasets) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2022.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borito/.pyenv/versions/3.10.7/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install prerequisites:\n",
    "%pip install flwr\n",
    "%pip install datasets\n",
    "%pip install flwr_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flwr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflwr\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client, ClientApp, NumPyClient\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metrics, Context\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flwr'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.simulation import run_simulation\n",
    "\n",
    "from lib import XyDataset\n",
    "\n",
    "## Create logger\n",
    "import logging\n",
    "from logging import DEBUG, ERROR, INFO, WARNING\n",
    "# Use the same logger as flower to ensure synchronization\n",
    "LOGGER_NAME = \"flwr\"\n",
    "# Set log level to DEBUG\n",
    "logging.getLogger(LOGGER_NAME).setLevel(logging.DEBUG)\n",
    "# Create a log object \n",
    "log = logging.getLogger(LOGGER_NAME).log\n",
    "#Example: log(INFO, \"INFO message\")\n",
    "\n",
    "# Check if you have a GPU available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing\n",
    "#### Load dataset UNSW-NB15\n",
    "\n",
    "Most works: binary classification (attack / not attack)\n",
    "\n",
    "Our task is more complex: multi-class attack classification (which attack) from connection features and measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load 10% of the training and testing datasets\n",
    "data_train = pd.read_csv('datasets/UNSW_NB15_training-set.csv').sample(frac=0.2, random_state=42)\n",
    "data_test = pd.read_csv('datasets/UNSW_NB15_testing-set.csv').sample(frac=0.2, random_state=42)\n",
    "\n",
    "# We merge the datasets to create our own train and test datasets \n",
    "data = pd.concat([data_train, data_test], ignore_index=True)\n",
    "\n",
    "# Drop columns\n",
    "data = data.drop(['id','label'], axis=1)\n",
    "data.rename(columns={'attack_cat': 'label'}, inplace=True)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_columns = data.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Print the lists\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "\n",
    "# Shuffle the dataset data\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Show the dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two DataFrames containing inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and labels\n",
    "X_sep = data.drop(['label'], axis=1)  # Features\n",
    "y_sep = data[['label']]  # Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Standard scaling of numerical variables in the input DataFrame\n",
    "\n",
    "$$z=\\frac{x-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Numerical feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_sep[numerical_columns] = scaler.fit_transform(X_sep[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode categorical variables in input and label DataFrames\n",
    "\n",
    "![image.png](res/onehot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical feature encoding\n",
    "\n",
    "from lib import one_hot_encode\n",
    "\n",
    "categorical_columns_X = [x for x in categorical_columns if x not in ['label'] ]\n",
    "X = one_hot_encode(X_sep, categorical_columns_X)\n",
    "\n",
    "categorical_columns_y = ['label']\n",
    "y = one_hot_encode(y_sep, categorical_columns_y)\n",
    "# y = y_sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, X contains the one-hot-encoded and scaled inputs, and y contains the one-hot-encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data size to build input and output layers of neural network\n",
    "input_size = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "print(f\"Input size: {input_size}, Number of classes: {num_classes}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create global training and test datasets \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets with 50% proportion\n",
    "# train_data, test_data = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=200 , random_state=42, shuffle=True) #test_size=0.995\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Train dataset shape:\", X_train.shape, type(X_train))\n",
    "print(\"Train labels shape:\", y_train.shape, type(y_train))\n",
    "print(\"Test dataset shape:\", X_test.shape, type(X_test))\n",
    "print(\"Test labels shape:\", y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Convert to PyTorch tensors\n",
    "# X_train = torch.FloatTensor(X_train.values)\n",
    "# X_test = torch.FloatTensor(X_test.values)\n",
    "# y_train = torch.LongTensor(y_train.values)\n",
    "# y_test = torch.LongTensor(y_test.values)\n",
    "\n",
    "# # # Observe the highly imbalanced sizes of training and test sets\n",
    "# print(\"Train dataset shape:\", X_train.shape, type(X_train))\n",
    "# print(\"Train labels shape:\", y_train.shape, type(y_train))\n",
    "# print(\"Test dataset shape:\", X_test.shape, type(X_test))\n",
    "# print(\"Test labels shape:\", y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one DataLoader for the whole test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST = 1024\n",
    "\n",
    "def make_testloader(X_test, y_test):\n",
    "    # Convert test data to PyTorch tensors\n",
    "    print(\"Test DataFrame dataset shape:\", X_test.shape, type(X_test))\n",
    "    print(\"Test DataFrame labels shape:\", y_test.shape, type(y_test))\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32) # TODO: This could be dtype=torch.long. Need to convert list elements to int\n",
    "\n",
    "    # Deprecated approach\n",
    "    # X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "    # y_test_tensor = torch.LongTensor(y_test.values) \n",
    "\n",
    "    # Observe the shapes of the input and output tensors\n",
    "    print(\"Test Tensor dataset shape:\", X_test_tensor.shape, type(X_test_tensor))\n",
    "    print(\"Test Tensor labels shape:\", y_test_tensor.shape, type(y_test_tensor))\n",
    "\n",
    "    # Create XyDataset dataset object from test sensors\n",
    "    test_dataset = XyDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create a DataLoader from the test dataset, which provides a batch iterator of size 1024\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)\n",
    "    print(type(testloader))\n",
    "\n",
    "    return testloader, X_test_tensor, y_test_tensor\n",
    "\n",
    "testloader, X_test_tensor, y_test_tensor = make_testloader(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select number of aggregation rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the isolated case this is the same as the number of epochs\n",
    "NUM_ROUNDS_IID = 50\n",
    "NUM_ROUNDS_NONIID = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performance of a centralized model trained on a centralized dataset\n",
    "\n",
    "Define a function to perform training and testing on a model for a certain number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import training, evaluation\n",
    "import torch.optim as optim\n",
    "from lib import FFNN_Tiny\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_and_test(input_size: int, num_classes: int, trainloader: DataLoader, testloader: DataLoader, num_rounds: int = 30, device: str = \"cpu\"): \n",
    "    '''\n",
    "    Trains and tests a FFNN_Tiny model on the given data loaders for a specified number of rounds.\n",
    "    '''\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = FFNN_Tiny(input_size, num_classes)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # For multi-class classification with one-hot output\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_metrics = pd.DataFrame()\n",
    "    test_metrics = pd.DataFrame()\n",
    "\n",
    "    for epoch in range(num_rounds):\n",
    "        train_metric = training(model, optimizer, criterion, trainloader, device)\n",
    "        train_metrics = pd.concat([train_metrics, pd.DataFrame([train_metric])], ignore_index=True)\n",
    "        print(\"Epoch\", epoch, \"Train\", train_metric)\n",
    "\n",
    "        test_metric = evaluation(model, criterion, testloader, device)\n",
    "        test_metrics = pd.concat([test_metrics, pd.DataFrame([test_metric])], ignore_index=True)\n",
    "        print(\"Epoch\", epoch, \"Test\", test_metric)\n",
    "\n",
    "    # Add a round column shifting the index to start from 1\n",
    "    train_metrics['round'] = train_metrics.index+1\n",
    "    test_metrics['round'] = test_metrics.index+1\n",
    "    \n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train_loader on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of local training on one partition from training dataset\n",
    "\n",
    "# Create DataLoader for training set\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "\n",
    "# Convert training data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32) # TODO: This could be dtype=torch.long. Need to convert list elements to int\n",
    "\n",
    "# Create XyDataset dataset object from test sensors\n",
    "train_dataset = XyDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute train and test metrics\n",
    "train_metrics_centralized, test_metrics_centralized = train_and_test(input_size, num_classes, train_loader, testloader, np.max([NUM_ROUNDS_IID,NUM_ROUNDS_NONIID]), DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize centralized model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import plot_metrics\n",
    "\n",
    "plot_metrics(train_metrics_centralized, test_metrics_centralized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on plots:\n",
    "1. No overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one Dataset object for the whole dataset, to feed into partitioners, which return individual DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create a Dataset object from the training dataset (Pandas DataFrame format)\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input\": X_train.values.tolist(),\n",
    "    \"output\": y_train.values.tolist(),\n",
    "    \"label\": y_train.values.argmax(axis=1).tolist() # This numerical encoding is needed for the partitioner. It cannot handle one-hot-encoded labels.\n",
    "})\n",
    "print(type(train_dataset), train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the per-partition label distribution after partitioning the training dataset with different strategies\n",
    "#### Observe different generation techniques of local label distribution. Label non-IIDness is one type of non-IIDness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "from flwr_datasets.partitioner import InnerDirichletPartitioner\n",
    "from flwr_datasets.partitioner import PathologicalPartitioner\n",
    "from flwr_datasets.partitioner import ShardPartitioner\n",
    "\n",
    "# NUM_CLIENTS = 90 with 1546 samples overall\n",
    "\n",
    "# Number of federated learning clients\n",
    "NUM_CLIENTS_IID = 40 #60\n",
    "NUM_CLIENTS_NONIID = 9\n",
    "\n",
    "## Create partitioners\n",
    "\n",
    "### IID Partitioner: Balanced size and IID labels\n",
    "iid_partitioner = IidPartitioner(num_partitions=NUM_CLIENTS_IID)\n",
    "# Actually this is a simple sharder: just split the dataset into equal parts without shuffling\n",
    "# If you need true IID, you have to remember shuffling the dataset before splitting\n",
    "# This Class also works directly with one-hot-encoded labels\n",
    "\n",
    "### Dirichlet Partitioner: Imbalanced size and non-IID labels\n",
    "dirichlet_partitioner = DirichletPartitioner(num_partitions=NUM_CLIENTS_NONIID, alpha=2, partition_by=\"label\", seed=4, self_balancing=True)\n",
    "\n",
    "### Shard Partitioner: Balanced size and non-IID labels\n",
    "# Operation: sort the dataset by label, then split it into num_partitions parts of size shard_size, then randomly assign num_shards_per_partition shards to each partition\n",
    "num_shards_per_partition = 5\n",
    "#Automatically calculated: shard_size = int(int(len(train_dataset)/NUM_CLIENTS_NONIID)/num_shards_per_partition)\n",
    "shard_partitioner = ShardPartitioner(num_partitions=NUM_CLIENTS_NONIID, partition_by=\"label\", num_shards_per_partition=num_shards_per_partition)\n",
    "# This Class does not work with one-hot-encoded labels\n",
    "\n",
    "### Pathological Partitioner: Imbalanced size and extremely non-IID labels\n",
    "pathological_partitioner = PathologicalPartitioner(num_partitions=NUM_CLIENTS_NONIID, partition_by=\"label\", seed=4, num_classes_per_partition=1, class_assignment_mode=\"deterministic\")#, class_assignment_mode=\"deterministic\"\n",
    "\n",
    "# The following lines are to check the partition label-distribution from the global dataset\n",
    "# Format entire dataset into HuggingFace format\n",
    "# dataset = Dataset.from_pandas(data)\n",
    "# iid_partitioner.dataset = dataset\n",
    "# dirichlet_partitioner.dataset = dataset\n",
    "# shard_partitioner.dataset = dataset\n",
    "# pathological_partitioner.dataset = dataset\n",
    "\n",
    "# Assign the dataset to the partitioner\n",
    "iid_partitioner.dataset = train_dataset\n",
    "dirichlet_partitioner.dataset = train_dataset\n",
    "shard_partitioner.dataset = train_dataset\n",
    "pathological_partitioner.dataset = train_dataset\n",
    "\n",
    "# Visualize the distributions\n",
    "from flwr_datasets.visualization import plot_label_distributions\n",
    "\n",
    "# Note: This generates an error because the partitioner expects a HuggingFace dataset Dataset\n",
    "# from torch.utils.data import TensorDataset\n",
    "# iid_partitioner.dataset = TensorDataset(X_train, y_train)\n",
    "list_of_partitioners = [iid_partitioner, shard_partitioner, dirichlet_partitioner, pathological_partitioner] #, pathological_partitioner, dirichlet_partitioner] pathological_partitioner dirichlet_partitioner\n",
    "\n",
    "for i, partitioner in enumerate(list_of_partitioners):\n",
    "    fig, ax, df = plot_label_distributions(\n",
    "        partitioner,\n",
    "        label_name=\"label\",\n",
    "        plot_type=\"bar\",\n",
    "        size_unit=\"absolute\",\n",
    "        partition_id_axis=\"x\",\n",
    "        legend=True,\n",
    "        verbose_labels=True,\n",
    "        title=f\"Per Partition Labels Distribution ({partitioner.__class__.__name__})\",\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function that returns a DataLoader object for the partition partition_id generated from partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import XyDataset\n",
    "\n",
    "def get_dataloader(partitioner, partition_id: int, BATCH_SIZE: int):\n",
    "\n",
    "    # Create a Local Dataset using the Partitioner to select a partition with id partition_id \n",
    "    partitioned_dataset = partitioner.load_partition(partition_id=partition_id)\n",
    "\n",
    "    # Convert partitioned data back to PyTorch Tensors for training\n",
    "    X_partition = torch.tensor([x for x in partitioned_dataset['input']], dtype=torch.float32)\n",
    "    y_partition = torch.tensor([y for y in partitioned_dataset['output']], dtype=torch.float32) # TODO: This could be dtype=torch.long. Need to convert list elements to int\n",
    "\n",
    "    # Report the shape of the partitioned data\n",
    "    print(f\"Created Partition {partition_id} - X: {X_partition.shape}, y: {y_partition.shape}\")\n",
    "\n",
    "    # Older approach\n",
    "    # X_partition = torch.FloatTensor([x for x in partitioned_dataset['input']])\n",
    "    # y_partition = torch.LongTensor([y for y in partitioned_dataset['output']])\n",
    "    \n",
    "    # TODO: Do both work?\n",
    "    # dataset = TensorDataset(X_partition, y_partition)\n",
    "    dataset = XyDataset(X_partition, y_partition)\n",
    "    \n",
    "    # Wraps the Dataset into a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the shard partitioner\n",
    "train_partitioner = iid_partitioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of performance on isolated nodes, no communication, no aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of local training on one partition from training dataset\n",
    "\n",
    "from lib import training, evaluation\n",
    "import torch.optim as optim\n",
    "from lib import FFNN_Tiny\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create DataLoader for partition with id partition_id=0\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "partition_id = 0\n",
    "train_loader = get_dataloader(train_partitioner, partition_id, BATCH_SIZE_TRAIN)\n",
    "\n",
    "def train_test_all(train_partitioner, num_clients, batch_size_train, num_rounds, device):\n",
    "    ''' Performs independent training and testing on all clients. '''\n",
    "\n",
    "    # Initialize return variables\n",
    "    train_metrics = pd.DataFrame()\n",
    "    test_metrics = pd.DataFrame()\n",
    "\n",
    "    for partition_id in range(0, num_clients):\n",
    "        train_loader = get_dataloader(train_partitioner, partition_id, batch_size_train)\n",
    "        train_metrics_partition, test_metrics_partition = train_and_test(input_size, num_classes, train_loader, testloader, num_rounds, device)\n",
    "        train_metrics_partition['client_id'] = partition_id\n",
    "        test_metrics_partition['client_id'] = partition_id\n",
    "        train_metrics = pd.concat([train_metrics, train_metrics_partition], ignore_index=True)\n",
    "        test_metrics = pd.concat([test_metrics, test_metrics_partition], ignore_index=True)\n",
    "    \n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on one client\n",
    "# train_metrics, test_metrics = train_test_all(train_partitioner, 0, BATCH_SIZE_TRAIN, NUM_ROUNDS_IID, DEVICE)\n",
    "\n",
    "# Train and test on all clients\n",
    "# train_metrics_iid, test_metrics_iid =  train_test_all(train_partitioner, NUM_CLIENTS_IID, BATCH_SIZE_TRAIN, NUM_ROUNDS_IID, DEVICE)\n",
    "train_metrics_iid, test_metrics_iid =  train_test_all(train_partitioner, 10, BATCH_SIZE_TRAIN, NUM_ROUNDS_IID, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the training and test performance in IID scenario without any user interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import plot_metrics\n",
    "from lib import plot_metrics_full\n",
    "\n",
    "# plot_metrics(train_metrics_iid, test_metrics_iid)\n",
    "# plot_metrics_full(train_metrics_iid, ('Avg. Test', test_metrics_iid))\n",
    "# plot_metrics_full(test_metrics_iid, ('Avg. Train', train_metrics_iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Flower Client class with distributed training and centralized evaluation\n",
    "\n",
    "At every round, the fit method is called. Then the updated parameters are collected with a get_parameters and sent to server for the aggregation.\n",
    "The fit method receives the parameters in input and overwrites the weights of the local model. Then performs a number of model updates based on gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Flower Client with distributed training and centralized evaluation\n",
    "\n",
    "from lib import get_parameters, set_parameters\n",
    "\n",
    "# Inherit NumpyClient ()\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, optimizer, criterion, train_loader, epochs_per_round):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.epochs_per_round = epochs_per_round\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.model)\n",
    "\n",
    "    # Update the model parameters with the received parameters and train the model for epochs_per_round epochs\n",
    "    def fit(self, parameters, config):\n",
    "\n",
    "        # Set the received parameters in the model\n",
    "        set_parameters(self.model, parameters)\n",
    "\n",
    "        # Train the model for epochs_per_round epochs\n",
    "        # TODO: this can become NUM_STEPS_PER_ROUND instead of NUM_EPOCHS\n",
    "        for _ in range(self.epochs_per_round):\n",
    "            train_metric = training(self.model, self.optimizer, self.criterion, self.train_loader, DEVICE)\n",
    "        return get_parameters(self.model), len(self.train_loader), train_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a \"Client Builder\" callback function\n",
    "Define a \"Client Builder\" callback function that returns a FlowerClient object with parameters specified in the Context\n",
    "For example, the context contains the node_config which can be used to fetch the partition_id for the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a device. Configuration is provided as a `Context` object.\"\"\"\n",
    "\n",
    "    # Initialize model\n",
    "    model = FFNN_Tiny(input_size, num_classes)\n",
    "\n",
    "    # Get node id\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    train_loader = get_dataloader(train_partitioner, partition_id, BATCH_SIZE_TRAIN) # train_partitioner is global\n",
    "\n",
    "    # Report client details\n",
    "    log(INFO, f\"Client {partition_id} created with {len(train_loader)} mini-batches of size {BATCH_SIZE_TRAIN}\") \n",
    "    \n",
    "    # Get Loss function (For multi-class classification with one-hot output)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Create a stateful optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Create and return a single Flower client representing a device\n",
    "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
    "    # to convert it to a subclass of `flwr.client.Client`\n",
    "    return FlowerClient(model, optimizer, criterion, train_loader, epochs_per_round=1).to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define centralized evaluation function for the server\n",
    "Important: note how the testloader is embedded in the function and the model is passed as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays, Scalar\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "# Used as global variables\n",
    "# X_test_tensor\n",
    "# y_test_tensor\n",
    "# BATCH_SIZE_TEST\n",
    "\n",
    "# The input is the model copy on the server and the output is the function that evaluates the model\n",
    "def get_centr_eval_fn(model, criterion):\n",
    "    \"\"\"Return a stateful evaluation function for server-side evaluation.\"\"\"\n",
    "    \n",
    "    # Create a test dataset object from raw tensors\n",
    "    test_dataset = XyDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create a DataLoader for the evaluation function on the server\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)    \n",
    "\n",
    "    # The evaluate function will be called after every round at the server\n",
    "    def centr_eval_fn(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \n",
    "        # model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        set_parameters(model, parameters)\n",
    "        log(INFO, \"Calling centralized aggregated model evaluation...\")\n",
    "        test_metric = evaluation(model, criterion, testloader, DEVICE)\n",
    "        log(INFO, \"Finished. Results will be at fit_progress\")\n",
    "\n",
    "        return test_metric['loss'], test_metric\n",
    "\n",
    "    # Return the stateful evaluation function that contains the test dataset\n",
    "    return centr_eval_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Federation Strategy\n",
    "\n",
    "Specify server-side parameters for the client's model aggregation and collection. After every aggregation, performs centralized evaluation by calling evaluate_fn.\n",
    "\n",
    "The fit method returns a list of tuples (number_of_examples, {metric_key: metric_value}) containing each client's metrics report.\n",
    "\n",
    "--> number_of_examples = length of dataset =  number of mini-batches per epoch (in mini-batch gradient descent)\n",
    "\n",
    "Example: [(15, {'accuracy': 0.4, 'loss': 0.2, 'round': 17, 'client_id': '56'}), (...), (...), ...]\n",
    "\n",
    "fit_progress shows the performance of the aggregated global model: (num_round, loss, custom_metrics, wall_clock_elapsed_time_evaluation_seconds)\n",
    "\n",
    "Example: (1, 0.6, {'loss': 0.6, 'accuracy': 0.4}, 15.096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the server strategy (e.g., FedAvg aggregation, etc.) with centralized evaluation and model initialization\n",
    "\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "from lib import all_metrics\n",
    "\n",
    "strategy = FedAvg(\n",
    "    fraction_fit = 1.0,  # Try to sample a proportion fraction_fit of available clients for training\n",
    "    min_fit_clients = NUM_CLIENTS_IID,  # Min number of clients to send their updates to the server before aggregation (this is different than fraction_fit: it is a minimum hard limit, fraction_fit is a desired proportion)\n",
    "    min_available_clients = NUM_CLIENTS_IID,  # Min number of clients that should be connected to the server (if not, the server waits)\n",
    "    fit_metrics_aggregation_fn = all_metrics,  # Report all metrics for centralized evaluation\n",
    "    fraction_evaluate = 0.0,  # No client evaluation\n",
    "    evaluate_metrics_aggregation_fn = None, # No client evaluation --> centralized evaluation\n",
    "    evaluate_fn = get_centr_eval_fn(FFNN_Tiny(input_size,num_classes).to(DEVICE), nn.BCEWithLogitsLoss()),  # Selects evaluation function (on centralized testset)\n",
    "    initial_parameters = ndarrays_to_parameters(get_parameters(FFNN_Tiny(input_size,num_classes)))  # Set initial model parameters (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the server builder function\n",
    "It takes the Context and returns a configured (e.g., number of rounds) ServerAppComponents object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    \"\"\"Construct components that set the ServerApp behaviour.\"\"\"\n",
    "\n",
    "    # Configure the server for NUM_ROUNDS_IID rounds of training (in the base class is the only param)\n",
    "    # Set a round timeout of 10 minutes (optional)\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS_IID, round_timeout=600) # NUM_ROUNDS_IID is a global variable\n",
    "\n",
    "    log(INFO, f\"Aggregation server is using strategy: {strategy.__class__.__name__}\")\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config) # strategy is a global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "\n",
    "print(backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation\n",
    "\n",
    "ServerApp and ClientApp objects are created on-the-fly \n",
    "\n",
    "1. Create the ServerApp wrapper object initialized using the ServerAppComponents object.\n",
    "The ServerApp wrapper takes the server builder function as a callback to which a context is passed and returns a ServerAppComponent object\n",
    "\n",
    "2. Create the ClientApp wrapper around the FlowerClient.\n",
    "The ClientApp wrapper takes the client builder function as a callback to which a context is passed and returns a FlowerClient object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_simulation(\n",
    "#     server_app=ServerApp(server_fn=server_fn),\n",
    "#     client_app=ClientApp(client_fn=client_fn),\n",
    "#     num_supernodes=2 # Should be NUM_CLIENTS, here we use 2 for testing\n",
    "#     backend_config=backend_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: the predefined FedAvg strategy class does not allow access to simulation metrics, it only shows in text form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom strategy FedAvgCustom\n",
    "This will allow each device and server to save the state of losses and metrics inside the Strategy object so that we can manipulate it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.common import Parameters\n",
    "\n",
    "# Defines a custom FedAvg strategy\n",
    "class FedAvgCustom(FedAvg):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    # def __init__(self, file_name: str, num_rounds: int, *args, **kwargs):\n",
    "    #     super().__init__(*args, **kwargs)\n",
    "        # self.file_name = file_name\n",
    "        # self.num_rounds = num_rounds\n",
    "\n",
    "        # Stateful lists of metrics for training and evaluation\n",
    "        self.train_metrics = pd.DataFrame()\n",
    "        self.test_metrics = pd.DataFrame()\n",
    "\n",
    "    def aggregate_fit(self, round, results, failures):\n",
    "        '''Log and save the individual client training metrics received by the server in a DataFrame'''\n",
    "\n",
    "        for client_id, res in results:\n",
    "            res.metrics[\"round\"] = round\n",
    "            res.metrics[\"client_id\"] = client_id.cid          \n",
    "            self.train_metrics = pd.concat([self.train_metrics, pd.DataFrame([res.metrics])], ignore_index=True)\n",
    "\n",
    "        # Run normal FedAvg aggregation\n",
    "        return super().aggregate_fit(round, results, failures) # returns aggregated model parameters and aggregated metrics\n",
    "\n",
    "    def evaluate(self, server_round: int, parameters: Parameters):\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "\n",
    "        # Call evaluation from the parent class (FedAvg): calls evaluate_fn passed to the strategy init (i.e., get_centr_eval_fn) that we already defined\n",
    "        _, test_metric = super().evaluate(server_round, parameters)\n",
    "                \n",
    "        # Append results of model testing in a stateful DataFrame\n",
    "        test_metric['round'] = server_round+1\n",
    "        self.test_metrics = pd.concat([self.test_metrics, pd.DataFrame([test_metric])], ignore_index=True)\n",
    "        \n",
    "        # (optional) If last round, save results to CSV\n",
    "        # if server_round == self.num_rounds:\n",
    "        #     with open(f\"{self.file_name}.json\", \"w\") as f:\n",
    "        #         import json\n",
    "        #         json.dump({\"loss\": self.loss_list, \"metrics\": self.metrics_list}, f)\n",
    "\n",
    "        return test_metric['loss'], test_metric\n",
    "\n",
    "# Create a new strategy\n",
    "strategy = FedAvgCustom(\n",
    "    fraction_fit = 1.0,  # Try to sample a proportion fraction_fit of available clients for training\n",
    "    min_fit_clients = NUM_CLIENTS_IID,  # Min number of clients to send their updates to the server before aggregation (this is different than fraction_fit: it is a minimum hard limit, fraction_fit is a desired proportion)\n",
    "    min_available_clients = NUM_CLIENTS_IID,  # Min number of clients that should be connected to the server (if not, the server waits)\n",
    "    fit_metrics_aggregation_fn = all_metrics,  # Report all metrics for centralized evaluation\n",
    "    fraction_evaluate = 0.0,  # No client evaluation\n",
    "    evaluate_metrics_aggregation_fn = None, # No client evaluation --> centralized evaluation\n",
    "    evaluate_fn = get_centr_eval_fn(FFNN_Tiny(input_size,num_classes).to(DEVICE), nn.BCEWithLogitsLoss()),  # Selects evaluation function (on centralized testset)\n",
    "    initial_parameters = ndarrays_to_parameters(get_parameters(FFNN_Tiny(input_size,num_classes)))  # Set initial model parameters (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run simulation with new strategy enhanced with data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_simulation(\n",
    "    server_app=ServerApp(server_fn=server_fn),\n",
    "    client_app=ClientApp(client_fn=client_fn),\n",
    "    num_supernodes=NUM_CLIENTS_IID,\n",
    "    backend_config=backend_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the simulation results out of the Strategy object and inspect it inside the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test_metrics_fl_iid = deepcopy(strategy.test_metrics)\n",
    "train_metrics_fl_iid = deepcopy(strategy.train_metrics)\n",
    "\n",
    "train_metrics_fl_iid\n",
    "test_metrics_fl_iid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize model training and testing performance for:\n",
    "1. clients' local models\n",
    "2. server's global model\n",
    "3. centralized model on centralized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize performance of Federated Learning on IID local datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import plot_metrics_full\n",
    "\n",
    "plot_metrics_full(\n",
    "    train_metrics_fl_iid,\n",
    "    ('Global Model Test', test_metrics_fl_iid),\n",
    "    # ('Centralized Train', train_metrics_centralized),\n",
    "    ('Centralized Test', test_metrics_centralized),\n",
    "    # ('Isolated Train', train_metrics_iid),\n",
    "    ('Isolated Test', test_metrics_iid)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat experiment for non-IID local datasets\n",
    "\n",
    "Change partitioner from iid_partitioner to a highly non-iid partitioner (pathological_partitioner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the shard partitioner\n",
    "train_partitioner = pathological_partitioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance in non federated scenario: local nodes perform training with the available dataset without any communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on all clients with pathological non-iid local dataset partitioning\n",
    "train_metrics_noniid, test_metrics_noniid = train_test_all(train_partitioner, NUM_CLIENTS_NONIID, BATCH_SIZE_TRAIN, NUM_ROUNDS_NONIID, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the training and test performance in non-IID scenario without any user interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import plot_metrics_full\n",
    "# plot_metrics(train_metrics_noniid, test_metrics_noniid)\n",
    "plot_metrics_full(train_metrics_noniid, ('Isolated Test', test_metrics_noniid) )\n",
    "plot_metrics_full(test_metrics_noniid, ('Isolated Train', train_metrics_noniid) )\n",
    "\n",
    "# Compare with IID partitioning\n",
    "# plot_metrics(train_metrics_iid, test_metrics_iid)\n",
    "# plot_metrics_full(train_metrics_iid, ('Avg. Test', test_metrics_iid))\n",
    "# plot_metrics_full(test_metrics_iid, ('Avg. Train', train_metrics_iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Test performance remains minimal with highly non-iid case and no model federation through device communication.\n",
    "\n",
    "Test if Federated Learning can improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import FFNN_Tiny\n",
    "\n",
    "# We must redefine the server strategy with the new partitioner\n",
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a device. Configuration is provided as a `Context` object.\"\"\"\n",
    "\n",
    "    # Initialize model\n",
    "    model = FFNN_Tiny(input_size, num_classes)\n",
    "\n",
    "    # Get node id\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    train_loader = get_dataloader(train_partitioner, partition_id, BATCH_SIZE_TRAIN) # train_partitioner is global\n",
    "\n",
    "    # Report client details\n",
    "    log(INFO, f\"Client {partition_id} created with {len(train_loader)} mini-batches of size {BATCH_SIZE_TRAIN}\") \n",
    "    \n",
    "    # Get Loss function (For multi-class classification with one-hot output)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Create a stateful optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Create and return a single Flower client representing a device\n",
    "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
    "    # to convert it to a subclass of `flwr.client.Client`\n",
    "    return FlowerClient(model, optimizer, criterion, train_loader, epochs_per_round=1).to_client()\n",
    "\n",
    "# Create a new strategy\n",
    "strategy = FedAvgCustom(\n",
    "    fraction_fit = 1.0,  # Try to sample a proportion fraction_fit of available clients for training\n",
    "    min_fit_clients = NUM_CLIENTS_NONIID,  # Min number of clients to send their updates to the server before aggregation (this is different than fraction_fit: it is a minimum hard limit, fraction_fit is a desired proportion)\n",
    "    min_available_clients = NUM_CLIENTS_NONIID,  # Min number of clients that should be connected to the server (if not, the server waits)\n",
    "    fit_metrics_aggregation_fn = all_metrics,  # Report all metrics for centralized evaluation\n",
    "    fraction_evaluate = 0.0,  # No client evaluation\n",
    "    evaluate_metrics_aggregation_fn = None, # No client evaluation --> centralized evaluation\n",
    "    evaluate_fn = get_centr_eval_fn(FFNN_Tiny(input_size,num_classes).to(DEVICE), nn.BCEWithLogitsLoss()),  # Selects evaluation function (on centralized testset)\n",
    "    initial_parameters = ndarrays_to_parameters(get_parameters(FFNN_Tiny(input_size,num_classes)))  # Set initial model parameters (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulation again with the non-IID partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_simulation(\n",
    "    server_app=ServerApp(server_fn=server_fn),\n",
    "    client_app=ClientApp(client_fn=client_fn),\n",
    "    num_supernodes=NUM_CLIENTS_NONIID,\n",
    "    backend_config=backend_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the simulation results out of the Strategy object and inspect it inside the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test_metrics_fl_noniid = deepcopy(strategy.test_metrics)\n",
    "train_metrics_fl_noniid = deepcopy(strategy.train_metrics)\n",
    "\n",
    "test_metrics_fl_noniid\n",
    "train_metrics_fl_noniid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize performance of Federated Learning on non-IID local datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib import plot_metrics_full\n",
    "\n",
    "plot_metrics_full(\n",
    "    train_metrics_fl_noniid,\n",
    "    ('Global Model Test', test_metrics_fl_noniid),\n",
    "    ('Centralized Train', train_metrics_centralized),\n",
    "    ('Centralized Test', test_metrics_centralized),\n",
    "    ('Isolated Train', train_metrics_noniid),\n",
    "    ('Isolated Test', test_metrics_noniid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
